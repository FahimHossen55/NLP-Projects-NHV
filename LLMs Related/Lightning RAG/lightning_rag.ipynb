{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"2312.13382.pdf\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"mixedbread-ai/mxbai-embed-large-v1\",\n",
    "    encode_kwargs = {'precision': 'binary'}\n",
    "    )\n",
    "one_bit_vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "one_bit_retriever = one_bit_vectorstore.as_retriever(\n",
    "                                                    search_kwargs={\"k\": 3}\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\n",
    "\"\"\")\n",
    "model = ChatGroq(groq_api_key=groq_api_key, model_name=\"mixtral-8x7b-32768\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chain = create_stuff_documents_chain(model, prompt)\n",
    "one_bit_retrieval_chain = create_retrieval_chain(one_bit_retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paper introduces DSPy, a system that enables generating harder few-shot examples to teach language models (LMs) to conduct challenging steps. It also presents a method called counterexample bootstrapping, which involves developing demonstrations that contain failed examples and traces to fix errors. These counterexamples are mixed with bootstrapped few-shot examples to help the LM avoid making the same mistakes without assertion-driven backtracking. Additionally, the paper discusses DSPy Assertions, which check for the correct answer's inclusion and verify the plausibility of answer choices.\n",
      "\n",
      "The paper also presents a new task called TweetGen, which generates tweets to answer questions derived from the HotPotQA data set. The TweetGen system includes a DSPy program with LM Assertions to ensure the generated tweets meet certain criteria, such as not having hashtags, including the correct answer, being within a character limit, being engaging, and being faithful to the context. The paper evaluates the task's performance across various metrics, including No Hashtags, Correct Answer Inclusion, Within Length, Engaging, and Faithful.\n",
      "CPU times: total: 219 ms\n",
      "Wall time: 1.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = one_bit_retrieval_chain.invoke({\"input\": \"What does the paper introduce?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"mixedbread-ai/mxbai-embed-large-v1\"\n",
    "    )\n",
    "normal_vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "normal_retriever = normal_vectorstore.as_retriever(\n",
    "                                                    search_kwargs={\"k\": 3}\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_retrieval_chain = create_retrieval_chain(normal_retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paper introduces several concepts and tools related to language model pipelines. Here are the main ones:\n",
      "\n",
      "1. DSPy: A framework for building language model pipelines that can handle complex tasks such as long-form question answering. It includes modules such as `dspy.Retrieve` for retrieving relevant passages and `dspy.ChainOfThought` for generating a series of reasoning steps.\n",
      "2. LongFormQAWithAssertions: A class in DSPy that implements a long-form question answering pipeline with two assertions: (1) every 1-2 sentences should have a citation, and (2) the text preceding a citation should be faithful to the cited reference. These assertions are implemented using `dspy.Suggest` statements, which can provide suggestions or warnings to the user.\n",
      "3. Citation Faithfulness: A metric for assessing the intrinsic performance of a language model pipeline. It checks if the text preceding each citation supports the cited context appropriately.\n",
      "4. QuizGen: A new task introduced in the paper, which involves turning questions from a dataset into quiz questions with answer choices. This task is represented by a simple program in DSPy that generates a set of answer choices based on a question-answer pair and a specified number of choices.\n",
      "5. LM Assertions: A tool for improving the robustness and safety of language model pipelines. It includes simple checks such as requiring every 1-2 sentences to have citations, and more sophisticated checks such as ensuring that the text preceding a citation is faithful to the cited context. LM Assertions can also be used to develop demonstrations that contain failed examples and traces to fix the errors, which can help the LM avoid making the same mistakes in the future.\n",
      "CPU times: total: 266 ms\n",
      "Wall time: 2.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = normal_retrieval_chain.invoke({\"input\": \"What is introduced in the paper?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_bit_vectorstore.save_local(\"one-bit\")\n",
    "normal_vectorstore.save_local(\"usual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "markdown-validation-crew",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
