{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsgf7x3GNADW",
        "outputId": "0e693684-16bd-45d4-9250-a9dd23f6af43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from groq)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Collecting requests>=2.32.2 (from datasets)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.5.0,>=2023.1.0 (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading groq-0.9.0-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, requests, pyarrow, h11, fsspec, dill, multiprocess, httpcore, httpx, groq, datasets\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.6.1\n",
            "    Uninstalling fsspec-2024.6.1:\n",
            "      Successfully uninstalled fsspec-2024.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.3.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "gcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2024.5.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 fsspec-2024.5.0 groq-0.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 multiprocess-0.70.16 pyarrow-17.0.0 requests-2.32.3 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "! pip install groq datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PDJAUHxooxo"
      },
      "source": [
        "# INSTRUCTION TUNING DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JRfsjo4ObBd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from groq import Groq\n",
        "from datasets import Dataset, DatasetDict, load_dataset\n",
        "import json\n",
        "\n",
        "topic = \"Machine Learning\"\n",
        "n_subtopics = 4\n",
        "n_questions = 10\n",
        "\n",
        "\n",
        "from groq import Groq\n",
        "\n",
        "client = Groq(\n",
        "    api_key=\"\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAvTXz90Mx6p",
        "outputId": "a7db5901-05fb-45bd-a39d-8d624378cbfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatCompletion(id='chatcmpl-19a7039b-c434-423f-b5a5-5bc634e3f567', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"Machine Learning\": \"Supervised Learning, Unsupervised Learning, Reinforcement Learning, Deep Learning\"\\n}', role='assistant', function_call=None, tool_calls=None))], created=1722941714, model='llama-3.1-70b-versatile', object='chat.completion', system_fingerprint='fp_9260b4bb2e', usage=CompletionUsage(completion_tokens=25, prompt_tokens=100, total_tokens=125, completion_time=0.1, prompt_time=0.023072095, queue_time=None, total_time=0.123072095), x_groq={'id': 'req_01j4kn8bbafwnb88tvzmvm198z'})\n",
            "{\n",
            "  \"Machine Learning\": \"Supervised Learning, Unsupervised Learning, Reinforcement Learning, Deep Learning\"\n",
            "}\n",
            "['Supervised Learning', ' Unsupervised Learning', ' Reinforcement Learning', ' Deep Learning']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 1. Subtopics Generation\n",
        "\n",
        "TOPIC_GENERATION_PROMPT_TEMPLATE = \"\"\"\\\n",
        "Given a topic, generate a list of {n_subtopics} subtopics that are related to the topic with topics as key.\n",
        "\n",
        "Topic: {topic}\n",
        "\n",
        "The list must be without numbers, and without any description of the subtopics. The subtopics should be separated by a comma. There must be no other text than the list.\n",
        "\n",
        "Return a JSON object with the list of subtopics separated by commas and a space.\n",
        "\"\"\"\n",
        "\n",
        "def generate_subtopics(client, topic, n_subtopics):\n",
        "    prompt = TOPIC_GENERATION_PROMPT_TEMPLATE.format(topic=topic, n_subtopics=n_subtopics)\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama-3.1-70b-versatile\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\",\n",
        "             \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0,\n",
        "        max_tokens=1024,\n",
        "        response_format={\"type\": \"json_object\"}\n",
        "    )\n",
        "    return response\n",
        "\n",
        "responses = generate_subtopics(client, topic=topic, n_subtopics=n_subtopics)\n",
        "print(responses)\n",
        "print(responses.choices[0].message.content)\n",
        "response_json = json.loads(responses.choices[0].message.content)\n",
        "subtopic_list = list(response_json.values())[0]\n",
        "subtopic_list = subtopic_list.split(\",\")\n",
        "print(subtopic_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiKgU3YoOYoQ",
        "outputId": "178188ee-3652-4a64-f250-09876943a747"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"questions\": \"What is supervised learning, How does supervised learning differ from unsupervised learning, What are the key components of a supervised learning algorithm, What is the role of labeled data in supervised learning, How do you handle missing or noisy data in supervised learning, What are some common supervised learning algorithms, How do you evaluate the performance of a supervised learning model, What is overfitting in supervised learning, How do you prevent overfitting in supervised learning, What are some real-world applications of supervised learning\"}\n",
            "['What is supervised learning', ' How does supervised learning differ from unsupervised learning', ' What are the key components of a supervised learning algorithm', ' What is the role of labeled data in supervised learning', ' How do you handle missing or noisy data in supervised learning', ' What are some common supervised learning algorithms', ' How do you evaluate the performance of a supervised learning model', ' What is overfitting in supervised learning', ' How do you prevent overfitting in supervised learning', ' What are some real-world applications of supervised learning']\n",
            "{\"questions\": \"What is the primary goal of unsupervised learning, How does unsupervised learning differ from supervised learning, What are some common techniques used in unsupervised learning, What is clustering in unsupervised learning, How does dimensionality reduction work in unsupervised learning, What is the role of feature extraction in unsupervised learning, Can unsupervised learning be used for anomaly detection, How does unsupervised learning handle missing data, What are some real-world applications of unsupervised learning, How does unsupervised learning evaluate its own performance\"}\n",
            "['What is the primary goal of unsupervised learning', ' How does unsupervised learning differ from supervised learning', ' What are some common techniques used in unsupervised learning', ' What is clustering in unsupervised learning', ' How does dimensionality reduction work in unsupervised learning', ' What is the role of feature extraction in unsupervised learning', ' Can unsupervised learning be used for anomaly detection', ' How does unsupervised learning handle missing data', ' What are some real-world applications of unsupervised learning', ' How does unsupervised learning evaluate its own performance']\n",
            "{\"questions\": \"What is the difference between reinforcement learning and supervised learning, How does reinforcement learning handle high-dimensional state spaces, What are the advantages of using deep reinforcement learning, Can reinforcement learning be used for multi-agent systems, How does reinforcement learning handle partial observability, What is the role of exploration in reinforcement learning, How does reinforcement learning handle delayed rewards, Can reinforcement learning be used for real-time decision making, What are the challenges of applying reinforcement learning to real-world problems, How does reinforcement learning handle non-stationary environments\"}\n",
            "['What is the difference between reinforcement learning and supervised learning', ' How does reinforcement learning handle high-dimensional state spaces', ' What are the advantages of using deep reinforcement learning', ' Can reinforcement learning be used for multi-agent systems', ' How does reinforcement learning handle partial observability', ' What is the role of exploration in reinforcement learning', ' How does reinforcement learning handle delayed rewards', ' Can reinforcement learning be used for real-time decision making', ' What are the challenges of applying reinforcement learning to real-world problems', ' How does reinforcement learning handle non-stationary environments']\n",
            "{\"questions\": \"What is the difference between deep learning and machine learning, How does deep learning improve image recognition, What are the applications of deep learning in natural language processing, Can deep learning be used for time series forecasting, How does deep learning handle overfitting, What is the role of activation functions in deep learning, How does deep learning differ from traditional neural networks, What are the challenges of training deep learning models, Can deep learning be used for recommender systems, How does deep learning improve speech recognition\"}\n",
            "['What is the difference between deep learning and machine learning', ' How does deep learning improve image recognition', ' What are the applications of deep learning in natural language processing', ' Can deep learning be used for time series forecasting', ' How does deep learning handle overfitting', ' What is the role of activation functions in deep learning', ' How does deep learning differ from traditional neural networks', ' What are the challenges of training deep learning models', ' Can deep learning be used for recommender systems', ' How does deep learning improve speech recognition']\n",
            "['What is supervised learning', ' How does supervised learning differ from unsupervised learning', ' What are the key components of a supervised learning algorithm', ' What is the role of labeled data in supervised learning', ' How do you handle missing or noisy data in supervised learning', ' What are some common supervised learning algorithms', ' How do you evaluate the performance of a supervised learning model', ' What is overfitting in supervised learning', ' How do you prevent overfitting in supervised learning', ' What are some real-world applications of supervised learning', 'What is the primary goal of unsupervised learning', ' How does unsupervised learning differ from supervised learning', ' What are some common techniques used in unsupervised learning', ' What is clustering in unsupervised learning', ' How does dimensionality reduction work in unsupervised learning', ' What is the role of feature extraction in unsupervised learning', ' Can unsupervised learning be used for anomaly detection', ' How does unsupervised learning handle missing data', ' What are some real-world applications of unsupervised learning', ' How does unsupervised learning evaluate its own performance', 'What is the difference between reinforcement learning and supervised learning', ' How does reinforcement learning handle high-dimensional state spaces', ' What are the advantages of using deep reinforcement learning', ' Can reinforcement learning be used for multi-agent systems', ' How does reinforcement learning handle partial observability', ' What is the role of exploration in reinforcement learning', ' How does reinforcement learning handle delayed rewards', ' Can reinforcement learning be used for real-time decision making', ' What are the challenges of applying reinforcement learning to real-world problems', ' How does reinforcement learning handle non-stationary environments', 'What is the difference between deep learning and machine learning', ' How does deep learning improve image recognition', ' What are the applications of deep learning in natural language processing', ' Can deep learning be used for time series forecasting', ' How does deep learning handle overfitting', ' What is the role of activation functions in deep learning', ' How does deep learning differ from traditional neural networks', ' What are the challenges of training deep learning models', ' Can deep learning be used for recommender systems', ' How does deep learning improve speech recognition']\n"
          ]
        }
      ],
      "source": [
        "QUESTION_PROMPT_TEMPLATE = \"\"\"\\\n",
        "Given a topic, generate {n_questions} questions that could be asked about that topic. Your response should be in a list format.\n",
        "\n",
        "Topic: {sub_topic}\n",
        "\n",
        "The list must be without numbers. The questions should be separated by a comma. There must be no other text than the list no [].\n",
        "\n",
        "Return a JSON object with the list of questions separated by commas and a space.\n",
        "\"\"\"\n",
        "def generate_questions(client, sub_topic, n_questions):\n",
        "    prompt = QUESTION_PROMPT_TEMPLATE.format(sub_topic=sub_topic, n_questions=n_questions)\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama-3.1-70b-versatile\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\",\n",
        "             \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0,\n",
        "        max_tokens=1024,\n",
        "        response_format={\"type\": \"json_object\"}\n",
        "    )\n",
        "    return response\n",
        "\n",
        "def question_generator(client, subtopic_list, n_question):\n",
        "    tasks = [generate_questions(client, subtopic, n_question) for subtopic in subtopic_list]\n",
        "    question_list = tasks\n",
        "    return question_list\n",
        "\n",
        "question_lists = question_generator(client, subtopic_list, n_questions)\n",
        "all_questions = []\n",
        "for responses in question_lists:\n",
        "    print(responses.choices[0].message.content)\n",
        "    response_json = json.loads(responses.choices[0].message.content)\n",
        "    question_list = list(response_json.values())[0]\n",
        "    question_list = question_list.split(\",\")\n",
        "    print(question_list)\n",
        "    all_questions.extend(question_list)\n",
        "print(all_questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DO0cMlsQTN-",
        "outputId": "5001c886-cd5c-4d4d-fa00-86f2988b450d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "40\n"
          ]
        }
      ],
      "source": [
        "print(len(all_questions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5hryIPGQJzP",
        "outputId": "34192f80-fc2b-4389-af0b-0ef15f7fe5a9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:00<00:00, 156358.02it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['Supervised learning is a type of machine learning where an algorithm is trained on labeled data to learn a mapping between inputs and outputs. The algorithm is shown examples of input data and their corresponding correct outputs, allowing it to learn patterns and relationships in the data. The goal is to enable the algorithm to make accurate predictions on new, unseen data. Supervised learning is commonly used in applications such as image classification, natural language processing, and regression analysis, where the algorithm is trained to predict a specific output based on input data.',\n",
              " 'Supervised learning and unsupervised learning are two main types of machine learning approaches. The key difference between them lies in the type of data used for training.\\n\\nIn supervised learning, the model is trained on labeled data, where the correct output is already known. The model learns to map inputs to outputs based on the labeled data, enabling it to make predictions on new, unseen data.\\n\\nIn contrast, unsupervised learning involves training the model on unlabeled data, where the model must find patterns or relationships on its own. This approach is often used for clustering, dimensionality reduction, or anomaly detection.',\n",
              " \"The key components of a supervised learning algorithm are:\\n\\n1. **Training Data**: A labeled dataset used to train the model.\\n2. **Model**: A mathematical function that maps inputs to outputs.\\n3. **Loss Function**: A measure of the difference between predicted and actual outputs.\\n4. **Optimizer**: An algorithm that adjusts the model's parameters to minimize the loss function.\\n5. **Evaluation Metric**: A measure of the model's performance, such as accuracy or mean squared error.\\n\\nThese components work together to enable the model to learn from the training data and make accurate predictions on new, unseen data.\",\n",
              " \"In supervised learning, labeled data plays a crucial role as it serves as the foundation for training a model. Labeled data consists of input data paired with their corresponding correct output labels. This data is used to train the model to learn the relationship between inputs and outputs, enabling it to make predictions on new, unseen data. The quality and quantity of labeled data directly impact the model's accuracy and performance. High-quality labeled data is essential for effective supervised learning, as it allows the model to learn from correct examples and make informed predictions.\",\n",
              " 'To handle missing or noisy data in supervised learning, several techniques can be employed:\\n\\n1. **Imputation**: Replace missing values with estimated values using mean, median, or regression-based methods.\\n2. **Data cleaning**: Remove noisy or inconsistent data points.\\n3. **Data augmentation**: Generate new data points to supplement the existing dataset.\\n4. **Regularization**: Use techniques like L1 or L2 regularization to reduce overfitting caused by noisy data.\\n5. **Robust loss functions**: Use loss functions that are less sensitive to outliers, such as Huber loss or absolute loss.\\n6. **Ensemble methods**: Combine multiple models trained on different subsets of the data to improve overall performance.',\n",
              " 'Some common supervised learning algorithms include:\\n\\n* Linear Regression: models a linear relationship between the input features and the target variable.\\n* Logistic Regression: models a binary classification problem using a logistic function.\\n* Decision Trees: a tree-based model that splits data into subsets based on feature values.\\n* Random Forest: an ensemble model that combines multiple decision trees.\\n* Support Vector Machines (SVMs): a model that finds the hyperplane that maximally separates classes.\\n* K-Nearest Neighbors (KNN): a model that predicts the target variable based on the majority vote of its k nearest neighbors.',\n",
              " \"To evaluate the performance of a supervised learning model, you can use various metrics and techniques. Here are some common methods:\\n\\n1. **Accuracy**: Measure the proportion of correctly classified instances.\\n2. **Precision**: Calculate the ratio of true positives to the sum of true positives and false positives.\\n3. **Recall**: Calculate the ratio of true positives to the sum of true positives and false negatives.\\n4. **F1-score**: Calculate the harmonic mean of precision and recall.\\n5. **Confusion Matrix**: Visualize the true positives, false positives, true negatives, and false negatives.\\n6. **Cross-validation**: Evaluate the model's performance on unseen data to prevent overfitting.\\n\\nChoose the metrics that best suit your problem and model.\",\n",
              " 'Overfitting in supervised learning occurs when a model is too complex and learns the noise in the training data, resulting in poor performance on new, unseen data. This happens when a model has too many parameters relative to the amount of training data, causing it to fit the training data too closely. As a result, the model becomes overly specialized to the training data and fails to generalize well to new data. Overfitting can be mitigated by techniques such as regularization, early stopping, and cross-validation.',\n",
              " \"To prevent overfitting in supervised learning, consider the following strategies:\\n\\n1. **Regularization**: Add a penalty term to the loss function to discourage large weights, such as L1 or L2 regularization.\\n2. **Data augmentation**: Increase the size of the training dataset by applying transformations to existing data, like rotation, scaling, or flipping.\\n3. **Early stopping**: Monitor the model's performance on a validation set and stop training when performance starts to degrade.\\n4. **Cross-validation**: Split the data into multiple folds and train on each fold to evaluate the model's generalizability.\\n5. **Ensemble methods**: Combine multiple models to reduce overfitting and improve overall performance.\",\n",
              " 'Supervised learning has numerous real-world applications across various industries. Some examples include:\\n\\n* Image classification: Self-driving cars use supervised learning to recognize traffic lights, pedestrians, and road signs.\\n* Speech recognition: Virtual assistants like Siri and Alexa rely on supervised learning to understand voice commands.\\n* Medical diagnosis: Supervised learning algorithms help doctors diagnose diseases by analyzing medical images and patient data.\\n* Credit risk assessment: Banks use supervised learning to evaluate creditworthiness based on financial data and credit history.\\n* Recommendation systems: Online platforms like Netflix and Amazon use supervised learning to suggest products based on user behavior.',\n",
              " 'The primary goal of unsupervised learning is to identify patterns, relationships, and structures in data without any prior knowledge of the expected output. It aims to discover hidden insights and group similar data points together, often through clustering, dimensionality reduction, or density estimation. Unlike supervised learning, which focuses on predicting a specific outcome, unsupervised learning seeks to understand the underlying characteristics of the data itself. This allows for the discovery of new features, anomalies, or trends that may not have been apparent through other methods.',\n",
              " \"Unsupervised learning differs from supervised learning in that it doesn't require labeled data. In supervised learning, the algorithm is trained on labeled data to learn a mapping between inputs and outputs. In contrast, unsupervised learning involves training an algorithm on unlabeled data to identify patterns, relationships, or groupings. The algorithm must discover the underlying structure of the data on its own, without any guidance from a teacher. This approach is useful for exploratory data analysis, clustering, and dimensionality reduction.\",\n",
              " \"Some common techniques used in unsupervised learning include:\\n\\n* Clustering: grouping similar data points together (e.g., k-means, hierarchical clustering)\\n* Dimensionality reduction: reducing the number of features in a dataset (e.g., PCA, t-SNE)\\n* Density estimation: estimating the underlying probability distribution of a dataset (e.g., Gaussian mixture models)\\n* Anomaly detection: identifying data points that don't fit the typical pattern (e.g., one-class SVM, local outlier factor)\\n* Association rule learning: identifying relationships between variables (e.g., Apriori, Eclat)\\n\\nThese techniques help uncover hidden patterns and relationships in data without prior knowledge of the expected output.\",\n",
              " \"In unsupervised learning, clustering is a technique used to group similar data points into clusters based on their features or attributes. The goal is to identify patterns or structures in the data that are not explicitly defined. Clustering algorithms, such as K-Means or Hierarchical Clustering, assign each data point to a cluster based on its similarity to other points. This helps to identify underlying relationships, anomalies, or trends in the data, allowing for a deeper understanding of the data's structure and characteristics. Clustering is often used in applications like customer segmentation, image classification, and gene expression analysis.\",\n",
              " 'Dimensionality reduction in unsupervised learning is a technique used to reduce the number of features or dimensions in a dataset while retaining the most important information. This is achieved through algorithms such as PCA (Principal Component Analysis), t-SNE (t-distributed Stochastic Neighbor Embedding), and Autoencoders. These methods identify the underlying patterns and relationships in the data, allowing for a lower-dimensional representation that captures the essential characteristics of the data. This reduced representation can be used for visualization, clustering, or classification tasks, making it easier to analyze and understand complex data.',\n",
              " 'In unsupervised learning, feature extraction is a crucial step that helps to identify and represent relevant patterns in the data. It involves transforming raw data into a more meaningful and condensed form, highlighting the most important features that distinguish between different groups or clusters. This process enables the model to learn the underlying structure of the data, reducing dimensionality and improving the efficiency of clustering or density estimation algorithms. Effective feature extraction can lead to better model performance, improved interpretability, and more accurate results in unsupervised learning tasks.',\n",
              " 'Yes, unsupervised learning can be used for anomaly detection. In unsupervised learning, the model is trained on normal data and learns to identify patterns. When new data is introduced, the model can detect deviations from these patterns, indicating anomalies. Techniques like One-Class SVM, Local Outlier Factor (LOF), and Isolation Forest can be used for anomaly detection in unsupervised learning. These methods can identify unusual data points without requiring labeled data, making them suitable for applications where anomalies are not well-defined or rare. This approach can be effective in detecting unknown or novel anomalies.',\n",
              " 'In unsupervised learning, missing data is typically handled using one of two approaches:\\n\\n1. **Listwise deletion**: Remove rows or samples with missing values, which can lead to biased results if the missing data is not random.\\n2. **Imputation**: Replace missing values with estimated values, such as mean, median, or mode, or use more advanced techniques like multiple imputation or machine learning algorithms.\\n\\nThe choice of approach depends on the nature of the data and the specific problem being addressed.',\n",
              " 'Unsupervised learning has numerous real-world applications. Some examples include:\\n\\n* Customer segmentation: Companies use clustering algorithms to group customers based on their behavior, demographics, and preferences, enabling targeted marketing and improved customer service.\\n* Anomaly detection: Unsupervised learning is used in fraud detection, identifying unusual patterns in financial transactions or network activity.\\n* Image and speech processing: Techniques like dimensionality reduction and clustering are applied to image and speech data to improve image and speech recognition systems.\\n* Gene expression analysis: Unsupervised learning helps identify patterns in gene expression data, aiding in the discovery of new genes and their functions.',\n",
              " \"Unsupervised learning evaluates its own performance through various metrics and techniques. One common approach is to use clustering evaluation metrics, such as silhouette score, calinski-harabasz index, and davies-bouldin index, to assess the quality of the clusters formed. Another approach is to use dimensionality reduction techniques, such as PCA or t-SNE, to visualize the data and evaluate the effectiveness of the model in reducing dimensionality. Additionally, metrics like entropy and mutual information can be used to evaluate the model's ability to capture underlying patterns and relationships in the data. These metrics provide a quantitative measure of the model's performance.\",\n",
              " 'The primary difference between reinforcement learning and supervised learning lies in the feedback mechanism.\\n\\nIn supervised learning, the model is trained on labeled data, where the correct output is provided for each input. The model learns to map inputs to outputs based on this labeled data.\\n\\nIn contrast, reinforcement learning involves an agent interacting with an environment to learn a policy that maximizes a reward signal. The agent receives feedback in the form of rewards or penalties, but not explicit labels. This allows the agent to learn from trial and error, exploring the environment to find the optimal policy.',\n",
              " 'Reinforcement learning (RL) handles high-dimensional state spaces using various techniques to reduce the dimensionality and improve learning efficiency. Some common approaches include:\\n\\n* Feature extraction: Using techniques like PCA, t-SNE, or autoencoders to reduce the dimensionality of the state space.\\n* Value function approximation: Using function approximators like neural networks to estimate the value function, which can handle high-dimensional state spaces.\\n* Exploration-exploitation trade-off: Using techniques like entropy regularization or curiosity-driven exploration to encourage exploration in high-dimensional spaces.\\n* Hierarchical reinforcement learning: Breaking down the problem into smaller sub-problems with lower-dimensional state spaces.',\n",
              " 'The advantages of using deep reinforcement learning include:\\n\\n* **Improved decision-making**: Deep reinforcement learning enables agents to learn complex decision-making strategies in dynamic environments.\\n* **Autonomous learning**: Agents can learn from experience and adapt to new situations without explicit programming.\\n* **Scalability**: Deep reinforcement learning can be applied to complex problems with large state and action spaces.\\n* **Flexibility**: Agents can learn to interact with multiple environments and tasks.\\n* **High performance**: Deep reinforcement learning can achieve state-of-the-art performance in various domains, such as games and robotics.',\n",
              " 'Yes, reinforcement learning (RL) can be applied to multi-agent systems. In multi-agent systems, multiple agents interact with each other and their environment to achieve a common or conflicting goal. RL can be used to train each agent to learn policies that maximize their cumulative reward. This can be done using techniques such as multi-agent Q-learning, actor-critic methods, or decentralized RL. However, training multiple agents simultaneously can be challenging due to the increased complexity of the problem and the need to balance individual and collective goals.',\n",
              " 'Reinforcement learning (RL) handles partial observability by using techniques that allow the agent to infer the state of the environment from incomplete or noisy observations. Some common approaches include:\\n\\n* Partially observable Markov decision processes (POMDPs): These models explicitly represent the uncertainty in the state of the environment.\\n* Hidden Markov models (HMMs): These models use probabilistic transitions to infer the underlying state from observations.\\n* Recurrent neural networks (RNNs): These networks can learn to represent the hidden state of the environment from sequential observations.\\n* Intrinsic motivation: This approach encourages the agent to explore and learn about the environment through curiosity-driven behavior.',\n",
              " \"In reinforcement learning, exploration is the process of trying out new actions or states to gather information about the environment. Its primary role is to balance the trade-off between exploitation (choosing the action that maximizes reward) and exploration (trying new actions to learn more). Exploration helps the agent to:\\n\\n* Discover new states or actions that lead to higher rewards\\n* Learn about the environment's dynamics and structure\\n* Avoid getting stuck in local optima\\n* Improve the overall performance of the agent\\n\\nEffective exploration is crucial for efficient learning and achieving optimal performance in reinforcement learning tasks.\",\n",
              " \"Reinforcement learning handles delayed rewards by using techniques that account for the time gap between actions and their consequences. One common approach is to use a discount factor, which reduces the value of future rewards as they are delayed. This encourages the agent to prioritize immediate rewards over future ones. Another approach is to use a temporal difference (TD) learning algorithm, which updates the agent's value function based on the difference between the expected and actual rewards received. This helps the agent learn from delayed rewards and adapt to changing environments.\",\n",
              " 'Yes, reinforcement learning (RL) can be used for real-time decision making. RL algorithms, such as Q-learning and SARSA, can be designed to learn from interactions with an environment and make decisions in real-time. This is particularly useful in applications where the environment is changing rapidly, such as in robotics, autonomous vehicles, and financial trading. However, RL requires a balance between exploration and exploitation, and can be computationally intensive. To achieve real-time decision making, RL algorithms can be optimized for speed, and techniques such as online learning and incremental learning can be employed.',\n",
              " \"The challenges of applying reinforcement learning to real-world problems include:\\n\\n* **Exploration-exploitation trade-off**: Balancing the need to explore new actions with the need to exploit known good actions.\\n* **High-dimensional state and action spaces**: Dealing with complex environments that require large amounts of data to learn from.\\n* **Partial observability**: Handling situations where the agent can't observe the entire state of the environment.\\n* **Scalability**: Scaling reinforcement learning algorithms to handle large, complex problems.\\n* **Safety and robustness**: Ensuring the agent behaves safely and robustly in unexpected situations.\",\n",
              " 'Reinforcement learning (RL) handles non-stationary environments by adapting to changes in the environment over time. This can be achieved through:\\n\\n1. **Online learning**: Updating the policy as new data arrives, allowing the agent to adapt to changing conditions.\\n2. **Meta-learning**: Learning to learn across multiple tasks or environments, enabling the agent to generalize to new situations.\\n3. **Robust optimization**: Minimizing the impact of changes in the environment by using techniques like regularization and robust loss functions.\\n4. **Transfer learning**: Leveraging knowledge gained in one environment to improve performance in another, similar environment.\\n\\nThese approaches enable RL agents to handle non-stationary environments and improve their performance over time.',\n",
              " 'The primary difference between deep learning and machine learning lies in their complexity and approach. Machine learning is a subset of artificial intelligence that uses algorithms to enable computers to learn from data without being explicitly programmed. It relies on traditional algorithms and techniques such as decision trees, random forests, and support vector machines. Deep learning, on the other hand, is a type of machine learning that uses neural networks with multiple layers to analyze and learn from complex data, particularly images and speech. This allows for more accurate and efficient processing of large datasets.',\n",
              " 'Deep learning improves image recognition by using neural networks with multiple layers to analyze and learn from large datasets of images. These networks can automatically detect and learn features such as edges, shapes, and textures, allowing them to recognize objects and patterns in images with high accuracy. The more data the network is trained on, the better it becomes at recognizing images. This approach has led to significant improvements in image recognition tasks, such as object detection, facial recognition, and image classification, outperforming traditional machine learning methods.',\n",
              " 'Deep learning has revolutionized natural language processing (NLP) with numerous applications. Some key areas include:\\n\\n* Sentiment analysis: identifying emotions and opinions in text\\n* Language translation: machine translation and language understanding\\n* Text summarization: condensing long documents into concise summaries\\n* Speech recognition: converting spoken words to text\\n* Chatbots and virtual assistants: conversational interfaces for customer service and more\\n* Named entity recognition: identifying and categorizing entities in text, such as people, places, and organizations\\n* Text classification: categorizing text into predefined categories, such as spam vs. non-spam emails.',\n",
              " 'Yes, deep learning can be used for time series forecasting. Techniques such as Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTM) networks, and Gated Recurrent Units (GRUs) are well-suited for modeling temporal dependencies in time series data. These models can learn complex patterns and relationships in the data, allowing for accurate predictions of future values. Additionally, techniques like Autoencoders and Generative Adversarial Networks (GANs) can be used for anomaly detection and forecasting. Deep learning has been successfully applied to various time series forecasting tasks, including stock prices, weather forecasting, and energy consumption.',\n",
              " \"Deep learning models are prone to overfitting, which occurs when a model is too complex and learns the noise in the training data rather than the underlying patterns. To handle overfitting, deep learning models employ several techniques:\\n\\n1. **Regularization**: Adding a penalty term to the loss function to discourage large weights.\\n2. **Dropout**: Randomly dropping out units during training to prevent over-reliance on individual units.\\n3. **Early Stopping**: Stopping training when the model's performance on the validation set starts to degrade.\\n4. **Data Augmentation**: Increasing the size of the training set by applying transformations to the existing data.\\n\\nThese techniques help prevent overfitting and improve the model's generalization to unseen data.\",\n",
              " 'Activation functions are a crucial component of deep learning models, serving as a gatekeeper between layers. They introduce non-linearity to the model, allowing it to learn complex relationships between inputs and outputs. Without activation functions, neural networks would be limited to linear transformations, unable to capture the intricacies of real-world data. Common activation functions include ReLU, Sigmoid, and Tanh, each with its own strengths and weaknesses. By introducing non-linearity, activation functions enable deep learning models to learn and represent a wide range of patterns, making them a fundamental building block of modern neural networks.',\n",
              " 'Deep learning differs from traditional neural networks in its architecture and capabilities. Traditional neural networks are shallow, with a limited number of layers (typically 1-2). In contrast, deep learning models have multiple layers (typically 10-20 or more), allowing them to learn complex patterns and representations in data. This enables deep learning models to achieve state-of-the-art performance in tasks such as image and speech recognition, natural language processing, and more. The increased depth and complexity of deep learning models also require more computational power and data to train.',\n",
              " 'The challenges of training deep learning models include:\\n\\n* **Vanishing Gradients**: gradients become too small to update model parameters effectively, hindering learning.\\n* **Overfitting**: models become too specialized to training data, failing to generalize to new data.\\n* **Computational Requirements**: large models require significant computational resources, making training time-consuming and expensive.\\n* **Data Quality**: poor-quality or insufficient training data can lead to suboptimal model performance.\\n* **Hyperparameter Tuning**: finding the optimal set of hyperparameters can be a time-consuming and iterative process.',\n",
              " 'Yes, deep learning can be used for recommender systems. In fact, it has become a popular approach in recent years. Deep learning models, such as neural collaborative filtering (NCF) and deep matrix factorization (DMF), can learn complex patterns and relationships in user-item interactions. These models can handle high-dimensional user and item features, and can even learn to represent users and items in a dense vector space. This allows for more accurate and personalized recommendations. Additionally, deep learning models can handle cold start problems and can be integrated with other recommender systems to improve performance.',\n",
              " 'Deep learning has revolutionized speech recognition by significantly improving its accuracy. It uses neural networks to learn complex patterns in speech data, allowing it to better distinguish between similar sounds and words. Deep learning models can learn to recognize patterns in speech that are not easily captured by traditional machine learning algorithms. This leads to improved recognition of out-of-vocabulary words, better handling of background noise, and more accurate transcription of spoken language. As a result, deep learning has enabled speech recognition systems to achieve human-like accuracy in many applications.']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 3. Responses Generation\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "RESPONSE_PROMPT_TEMPLATE = \"\"\"\\\n",
        "Given a question, generate an answer which should be less than 100 words that could be given to that question.\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Your Answer:\n",
        "\"\"\"\n",
        "def generate_responses(client, question):\n",
        "    prompt = RESPONSE_PROMPT_TEMPLATE.format(question=question)\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama-3.1-8b-instant\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\",\n",
        "             \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0,\n",
        "        top_p=0.7,\n",
        "        max_tokens=1024\n",
        "    )\n",
        "    return response\n",
        "\n",
        "def response_generator(client, question_list):\n",
        "    tasks = [generate_responses(client, question) for question in all_questions]\n",
        "    response_list = tasks\n",
        "    return response_list\n",
        "\n",
        "answer_list = response_generator(client, all_questions)\n",
        "answer_list = [response.choices[0].message.content for response in tqdm(answer_list)]\n",
        "answer_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNMr593cR2eT"
      },
      "outputs": [],
      "source": [
        "qa_pair_list = []\n",
        "for question, answer in zip(all_questions, answer_list):\n",
        "    qa_pair_list.append(\n",
        "        {\n",
        "            \"question\": question,\n",
        "            \"answer\": answer\n",
        "        }\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UWMu-OmSd4Z",
        "outputId": "786bec44-91c8-48ab-a15e-e5d556ebe0b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'What is supervised learning',\n",
              " 'answer': 'Supervised learning is a type of machine learning where an algorithm is trained on labeled data to learn a mapping between inputs and outputs. The algorithm is shown examples of input data and their corresponding correct outputs, allowing it to learn patterns and relationships in the data. The goal is to enable the algorithm to make accurate predictions on new, unseen data. Supervised learning is commonly used in applications such as image classification, natural language processing, and regression analysis, where the algorithm is trained to predict a specific output based on input data.'}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qa_pair_list[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMlPPci8RwDm"
      },
      "outputs": [],
      "source": [
        "with open('synthetic_data.jsonl', 'w') as f:\n",
        "    for item in qa_pair_list:\n",
        "        f.write(json.dumps(item))\n",
        "        f.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dsHgADJS16o",
        "outputId": "8342b11d-25b5-4aa1-c9bf-ff7b254514b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "40\n"
          ]
        }
      ],
      "source": [
        "print(len(qa_pair_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "e7755ec5298d409da79aee955cf30e79",
            "abae31f1c73a4ec2b54082081c8adbb1",
            "c0c17c1d7db641fcab64e024c7bd3d94",
            "90d1756b8884404db5d939f53af4248b",
            "f342b050bab14962bcc8f526517e0bc5",
            "59bfdc4b394849f5b4718b331592e9ac",
            "1885dbfa1c214e8582245d5e56c64fda",
            "a0daa3aa4ab04a5e904caf66e8acedf8",
            "7db09f05374442ca9a8ccebc06ede04c",
            "fd88b84983c345e4b85efcd7d2955c68",
            "bf838c413e2048b495904fb3d541888f",
            "2aa90204f93a405abe75b114f43f6bd0",
            "53213fbf0e364198a80f983109b08412",
            "63825ba53a964a2591e833f65e25abfc",
            "b95b5767bbbb474c9f8caf9b97594d78",
            "7a2bd00b073a4148944dae6f40909e86",
            "2df67871613b4300b2cd0ed78512d65d",
            "5f5b36a204a44e5a83923954dc8bce65",
            "64be8e3204a846f4a5d1cda89502089f",
            "68201dcaaa9142508dfe1699cea0d2f7",
            "ffe3bfe50f2b4b1c8856e2a4f82d0c06",
            "d49df301fcc2428196d44cc2029566bd"
          ]
        },
        "id": "C0-wYFGZShlX",
        "outputId": "83fd7977-2c70-467d-d6c0-bc978b4f08ad"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7755ec5298d409da79aee955cf30e79",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2aa90204f93a405abe75b114f43f6bd0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/datasets/Vasanth/synthetic-llama-datagen/commit/da2a61537e7811663b38a68937d995c211d249c1', commit_message='Upload dataset', commit_description='', oid='da2a61537e7811663b38a68937d995c211d249c1', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = Dataset.from_list(qa_pair_list)\n",
        "dataset_dict = DatasetDict({\"train\": dataset})\n",
        "dataset_dict.push_to_hub(\"Vasanth/synthetic-llama-datagen\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOWlvN0fol6n"
      },
      "source": [
        "# PREFERENCE DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1S769vLHTneI"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from datasets import load_dataset\n",
        "import groq\n",
        "from rich import print\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "import os\n",
        "load_dotenv(find_dotenv())\n",
        "\n",
        "os.environ[\"HF_TOKEN\"] = os.getenv(\"HF_TOKEN\")\n",
        "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQQ_API_KEY\")\n",
        "\n",
        "# Load a real dataset from Hugging Face\n",
        "dataset = load_dataset(\"squad_v2\", split=\"train\")\n",
        "\n",
        "# Convert dataset to list of dictionaries\n",
        "json_data = dataset.select(range(100)).to_dict()\n",
        "\n",
        "print(\"Dataset Rows:\", len(json_data['id']))\n",
        "# print({key: json_data[key][0] for key in json_data})\n",
        "\n",
        "# Function to format the input for the model\n",
        "def format_input(context, question):\n",
        "    return (\n",
        "        \"### Context:\\n\" + context +\n",
        "        (\"\\n\\n### Question:\\n\" + question if question else \"\")\n",
        "    )\n",
        "\n",
        "# Initialize the Ollama client\n",
        "client = groq.Groq()  # Replace with your actual API key if required\n",
        "\n",
        "# Initialize new keys in the json_data dictionary\n",
        "json_data['rejected'] = [''] * len(json_data['id'])\n",
        "json_data['chosen'] = [''] * len(json_data['id'])\n",
        "\n",
        "# Process each entry in the dataset\n",
        "for i in range(len(json_data['id'])):\n",
        "    context = json_data['context'][i]\n",
        "    question = json_data['question'][i]\n",
        "    answer = json_data['answers'][i]['text'][0] if json_data['answers'][i]['text'] else \"No answer\"\n",
        "\n",
        "    print(\"Rejected Answer:\", answer)\n",
        "\n",
        "    prompt_text = format_input(context, question)\n",
        "\n",
        "    prompt = (\n",
        "        f\"Rewrite `{prompt_text}` output to be concise and clear: {answer}. \"\n",
        "        \"Ensure the response is easy to understand, professional and as a full sentense. Just respond only with the Answer\"\n",
        "    )\n",
        "\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt,\n",
        "            }\n",
        "        ],\n",
        "        model=\"llama-3.1-8b-instant\",\n",
        "    )\n",
        "\n",
        "    response = chat_completion.choices[0].message.content\n",
        "    chosen_answer = response\n",
        "    print(\"Chosen Answer:\", chosen_answer)\n",
        "\n",
        "    json_data['rejected'][i] = answer\n",
        "    json_data['chosen'][i] = chosen_answer\n",
        "\n",
        "# Convert back to dictionary format expected by json.dump\n",
        "final_data = [{key: json_data[key][i] for key in json_data} for i in range(len(json_data['id']))]\n",
        "\n",
        "with open(\"preference_dataset.json\", \"w\") as file:\n",
        "    json.dump(final_data, file, indent=4)\n",
        "\n",
        "new_data = load_dataset(\"json\", data_files=[\"preference_dataset.json\"])\n",
        "new_data.push_to_hub(\"Vasanth/squad-demo-preference-dataset\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1885dbfa1c214e8582245d5e56c64fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2aa90204f93a405abe75b114f43f6bd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_53213fbf0e364198a80f983109b08412",
              "IPY_MODEL_63825ba53a964a2591e833f65e25abfc",
              "IPY_MODEL_b95b5767bbbb474c9f8caf9b97594d78"
            ],
            "layout": "IPY_MODEL_7a2bd00b073a4148944dae6f40909e86"
          }
        },
        "2df67871613b4300b2cd0ed78512d65d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53213fbf0e364198a80f983109b08412": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2df67871613b4300b2cd0ed78512d65d",
            "placeholder": "​",
            "style": "IPY_MODEL_5f5b36a204a44e5a83923954dc8bce65",
            "value": "Creating parquet from Arrow format: 100%"
          }
        },
        "59bfdc4b394849f5b4718b331592e9ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f5b36a204a44e5a83923954dc8bce65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63825ba53a964a2591e833f65e25abfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64be8e3204a846f4a5d1cda89502089f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68201dcaaa9142508dfe1699cea0d2f7",
            "value": 1
          }
        },
        "64be8e3204a846f4a5d1cda89502089f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68201dcaaa9142508dfe1699cea0d2f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a2bd00b073a4148944dae6f40909e86": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7db09f05374442ca9a8ccebc06ede04c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90d1756b8884404db5d939f53af4248b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd88b84983c345e4b85efcd7d2955c68",
            "placeholder": "​",
            "style": "IPY_MODEL_bf838c413e2048b495904fb3d541888f",
            "value": " 1/1 [00:00&lt;00:00,  2.32it/s]"
          }
        },
        "a0daa3aa4ab04a5e904caf66e8acedf8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abae31f1c73a4ec2b54082081c8adbb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59bfdc4b394849f5b4718b331592e9ac",
            "placeholder": "​",
            "style": "IPY_MODEL_1885dbfa1c214e8582245d5e56c64fda",
            "value": "Uploading the dataset shards: 100%"
          }
        },
        "b95b5767bbbb474c9f8caf9b97594d78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffe3bfe50f2b4b1c8856e2a4f82d0c06",
            "placeholder": "​",
            "style": "IPY_MODEL_d49df301fcc2428196d44cc2029566bd",
            "value": " 1/1 [00:00&lt;00:00, 28.98ba/s]"
          }
        },
        "bf838c413e2048b495904fb3d541888f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0c17c1d7db641fcab64e024c7bd3d94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0daa3aa4ab04a5e904caf66e8acedf8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7db09f05374442ca9a8ccebc06ede04c",
            "value": 1
          }
        },
        "d49df301fcc2428196d44cc2029566bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7755ec5298d409da79aee955cf30e79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_abae31f1c73a4ec2b54082081c8adbb1",
              "IPY_MODEL_c0c17c1d7db641fcab64e024c7bd3d94",
              "IPY_MODEL_90d1756b8884404db5d939f53af4248b"
            ],
            "layout": "IPY_MODEL_f342b050bab14962bcc8f526517e0bc5"
          }
        },
        "f342b050bab14962bcc8f526517e0bc5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd88b84983c345e4b85efcd7d2955c68": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffe3bfe50f2b4b1c8856e2a4f82d0c06": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
