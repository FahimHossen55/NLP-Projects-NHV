{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI \n",
    "MODEL=\"gpt-4o\"\n",
    "client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEXT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Let's break down the problem step-by-step:\n",
      "\n",
      "1. You started with 2 apples.\n",
      "2. Your father gave you 2 more apples. Now you have 2 + 2 = 4 apples.\n",
      "3. You ate 3 apples. Now you have 4 - 3 = 1 apple.\n",
      "4. Then you gave 1 apple to your mother. Now you have 1 - 1 = 0 apples.\n",
      "\n",
      "So, you have 0 apples left.\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=MODEL,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello! I have 2 apples. My father gave me 2. I ate 3. Gave 1 to my mother. How many do I have?\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMAGE_DATA - BASE64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The picture shows a serene natural scene featuring a small waterfall cascading into a pool of water surrounded by lush green vegetation. The area appears to be a tranquil spot in a forest or jungle, with rocks and foliage adding to the picturesque setting. The water is clear, and the overall atmosphere is peaceful and refreshing.\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "\n",
    "IMAGE_PATH = \"complex_nature.jpg\"\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "base64_image = encode_image(IMAGE_PATH)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"What's the picture about?\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"}\n",
    "            }\n",
    "        ]}\n",
    "    ],\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMAGE DATA - URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The picture depicts a serene natural scene featuring a small waterfall cascading into a calm pool of water. The surrounding area is lush with green vegetation, including ferns and other plants, creating a tranquil and picturesque environment. The water appears clear, and there is a rock visible in the pool, adding to the natural beauty of the scene.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"What's the picture about?\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": \"https://thumbs.dreamstime.com/b/waterfall-sossegada-tourist-complex-capit%C3%B3lio-mg-brazil-december-beautiful-small-surrounded-plants-natural-beauty-212704578.jpg\"}\n",
    "            }\n",
    "        ]}\n",
    "    ],\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIDEO SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in C:/Users/vasan/Videos/Captures/cut.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Extracted 12 frames\n",
      "Extracted audio to C:/Users/vasan/Videos/Captures/cut.mp3\n",
      "The frames from the video show a document titled \"YouTube_Video_Creation_Report\" which lists details about various tutorial videos. Here is a summary of the content:\n",
      "\n",
      "### YouTube Video Creation Report\n",
      "\n",
      "#### Video 1\n",
      "- **Title:** Creal: Complete Crash Course for Beginners\n",
      "- **View Count:** N/A\n",
      "- **Likes Count:** N/A\n",
      "- **Channel Subscriber Count:** N/A\n",
      "- **Date Published:** N/A\n",
      "- **Link:** [Watch Here](https://www.youtube.com/watch?v=9bZkp7q19f0)\n",
      "\n",
      "#### Video 2\n",
      "- **Title:** Creal: Step-by-Step | Complete Course for Beginners\n",
      "- **View Count:** N/A\n",
      "- **Likes Count:** N/A\n",
      "- **Channel Subscriber Count:** N/A\n",
      "- **Date Published:** N/A\n",
      "- **Link:** [Watch Here](https://www.youtube.com/watch?v=9bZkp7q19f0)\n",
      "\n",
      "#### Video 3\n",
      "- **Title:** Creal Tutorial for Beginners: Learn How to Use Latest Creal Features\n",
      "- **View Count:** N/A\n",
      "- **Likes Count:** N/A\n",
      "- **Channel Subscriber Count:** N/A\n",
      "- **Date Published:** N/A\n",
      "- **Link:** [Watch Here](https://www.youtube.com/watch?v=9bZkp7q19f0)\n",
      "\n",
      "#### Video 4\n",
      "- **Title:** Creal + Groq Tutorial: Crash Course for Beginners\n",
      "- **View Count:** N/A\n",
      "- **Likes Count:** N/A\n",
      "- **Channel Subscriber Count:** N/A\n",
      "- **Date Published:** N/A\n",
      "- **Link:** [Watch Here](https://www.youtube.com/watch?v=9bZkp7q19f0)\n",
      "\n",
      "Each video appears to be a tutorial aimed at beginners, focusing on different aspects of using Creal and Groq. The view counts, likes, channel subscriber counts, and dates published are not available. All videos share the same YouTube link.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from moviepy.editor import VideoFileClip\n",
    "import time\n",
    "import base64\n",
    "\n",
    "VIDEO_PATH = \"C:/Users/vasan/Videos/Captures/cut.mp4\"\n",
    "\n",
    "def process_video(video_path, seconds_per_frame=2):\n",
    "    base64Frames = []\n",
    "    base_video_path, _ = os.path.splitext(video_path)\n",
    "\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    frames_to_skip = int(fps * seconds_per_frame)\n",
    "    curr_frame=0\n",
    "\n",
    "    while curr_frame < total_frames - 1:\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, curr_frame)\n",
    "        success, frame = video.read()\n",
    "        if not success:\n",
    "            break\n",
    "        _, buffer = cv2.imencode(\".jpg\", frame)\n",
    "        base64Frames.append(base64.b64encode(buffer).decode(\"utf-8\"))\n",
    "        curr_frame += frames_to_skip\n",
    "    video.release()\n",
    "\n",
    "    audio_path = f\"{base_video_path}.mp3\"\n",
    "    clip = VideoFileClip(video_path)\n",
    "    clip.audio.write_audiofile(audio_path, bitrate=\"32k\")\n",
    "    clip.audio.close()\n",
    "    clip.close()\n",
    "\n",
    "    print(f\"Extracted {len(base64Frames)} frames\")\n",
    "    print(f\"Extracted audio to {audio_path}\")\n",
    "    return base64Frames, audio_path\n",
    "\n",
    "base64Frames, audio_path = process_video(VIDEO_PATH, seconds_per_frame=1)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are generating a video summary. Please provide a summary of the video. Respond in Markdown.\"},\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        \"These are the frames from the video.\",\n",
    "        *map(lambda x: {\"type\": \"image_url\", \n",
    "                        \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, base64Frames)\n",
    "        ],\n",
    "    }\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUDIO SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The speaker discusses their latest project, a crew AI application designed to automate several tasks for their YouTube channel. The application focuses on automating four key steps: title creation, description creation, thumbnail creation, and tags identification. The speaker uses Google API, ChargeBT for LLM, and crew AI for the agent framework. The application analyzes top-performing videos related to a given title and generates optimized titles, descriptions, thumbnail prompts, and relevant tags. The speaker expresses satisfaction with the framework and invites viewers to check the link in the description or comment section for a detailed explanation of the code and architecture.\n"
     ]
    }
   ],
   "source": [
    "transcription = client.audio.transcriptions.create(\n",
    "    model=\"whisper-1\",\n",
    "    file=open(audio_path, \"rb\"),\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "    {\"role\": \"system\", \"content\":\"\"\"You are generating a transcript summary. Create a summary of the provided transcription. Respond in Markdown.\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"text\", \"text\": f\"The audio transcription is: {transcription.text}\"}\n",
    "        ],\n",
    "    }\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUDIO + VIDEO SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Video Summary\n",
      "\n",
      "The video showcases a project where the creator has developed a Crew.ai application. The frames from the video display a detailed report of various YouTube tutorial videos related to Crew.ai, including their titles, view counts, URLs, and publication dates. The report is organized in a table format, listing multiple videos aimed at beginners to help them learn and use Crew.ai effectively.\n",
      "\n",
      "#### Key Points:\n",
      "1. **Project Overview**: The creator introduces their latest project, a Crew.ai application.\n",
      "2. **Video Report**: The frames show a comprehensive report of YouTube tutorials on Crew.ai.\n",
      "3. **Tutorial Details**:\n",
      "   - Titles: Various titles such as \"CrewAI Tutorial: Complete Crash Course for Beginners\" and \"CrewAI Step-by-Step | Complete Course for Beginners\".\n",
      "   - View Counts: Information on the number of views each video has received.\n",
      "   - URLs: Links to the YouTube videos.\n",
      "   - Publication Dates: Dates when the videos were published.\n",
      "4. **Purpose**: The report aims to provide resources for beginners to learn and use Crew.ai.\n",
      "\n",
      "The video serves as a guide for those interested in learning Crew.ai, offering a curated list of educational resources.\n"
     ]
    }
   ],
   "source": [
    "transcription = client.audio.transcriptions.create(\n",
    "    model=\"whisper-1\",\n",
    "    file=open(audio_path, \"rb\"),\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "    {\"role\": \"system\", \"content\":\"\"\"You are generating a video summary. Create a summary of the provided video and its transcript. Respond in Markdown\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        \"These are the frames from the video.\",\n",
    "        *map(lambda x: {\"type\": \"image_url\", \n",
    "                        \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, base64Frames),\n",
    "                        {\"type\": \"text\", \"text\": f\"The audio transcription is: {transcription.text}\"}\n",
    "        ],\n",
    "    }\n",
    "],\n",
    "    temperature=0,\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUDIO + VIDEO QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both QA:\n",
      "The person is discussing about the \"CrewaI\" framework.\n"
     ]
    }
   ],
   "source": [
    "qa_both_response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "    {\"role\": \"system\", \"content\":\"\"\"Use the video and transcription to answer the provided question.\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        \"These are the frames from the video.\",\n",
    "        *map(lambda x: {\"type\": \"image_url\", \n",
    "                        \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, base64Frames),\n",
    "                        {\"type\": \"text\", \"text\": f\"The audio transcription is: {transcription.text}\"},\n",
    "        \"What is the framework the person is discussing about\"\n",
    "        ],\n",
    "    }\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "print(\"Both QA:\\n\" + qa_both_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "markdown-validation-crew",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
